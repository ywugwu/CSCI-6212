# Assessing GPT-4's Image Understanding Limitations

## Introduction
This study briefly investigates the limitations of GPT-4's vision model. 

Despite its superior performance shown in multimodal context understanding, we wonder if GPT-4 would struggle with certain visual tasks, like its deficiency in tackling math problems. 

In this study, we locate three tasks: object counting, image matching, and minor visual perturbation detection that GPT-4 fails and show concrete examples in the following sections.


## Tasks
### Object Counting
- Explain the criteria for choosing your images.
- Mention the variety and types of images used.

### Image Matching
- Detail how you used GPT-4 to analyze the images.
- Describe the process of comparing GPT-4's interpretations with human analysis or factual information.

### Perturbation Detection

## Findings (Limitations Identified)

- Highlight specific examples where GPT-4 failed or was inaccurate in its interpretation.
- Use images and responses to illustrate these points.



<img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/count_colors.png?raw=True" height="480">

## References

- OpenAI et al. (2023). *GPT-4 Technical Report*. arXiv:2303.08774 [cs.CL]. Available at: [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
