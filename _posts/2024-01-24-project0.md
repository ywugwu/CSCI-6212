# Assessing GPT-4's Image Understanding Limitations

## Introduction
This study investigates the limitations of GPT-4's vision model. Despite its effectiveness in multimodal context understanding, GPT-4, like its struggles with complex math, faces challenges in certain visual tasks. We will explore these limitations through tasks like object counting, image matching, and minor visual perturbation detection, providing counterexamples of GPT-4's performance.

## Tasks
### Object Counting
- Explain the criteria for choosing your images.
- Mention the variety and types of images used.

### Image Matching
- Detail how you used GPT-4 to analyze the images.
- Describe the process of comparing GPT-4's interpretations with human analysis or factual information.

### Perturbation Detection

## Findings (Limitations Identified)

- Highlight specific examples where GPT-4 failed or was inaccurate in its interpretation.
- Use images and responses to illustrate these points.



<img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/count_colors.png?raw=True" height="480">

![img](https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/count_colors.png?raw=True)
## References

- OpenAI et al. (2023). *GPT-4 Technical Report*. arXiv:2303.08774 [cs.CL]. Available at: [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
