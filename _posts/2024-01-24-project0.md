# Assessing the Limitations of GPT-4's Vision Model

## Introduction
This study briefly investigates the limitations of GPT-4's vision model. 

Despite its superior performance shown in multimodal context understanding, we wonder if GPT-4 would struggle with certain visual tasks, like its deficiency in tackling math problems. 

In this study, we locate three tasks: object counting, image matching, and minor visual perturbation detection that GPT-4 fails, and we show concrete examples in the following sections.


## Hard Tasks for GPT4's Vision Model
### Object Counting
We define the object counting task as asking `how many **[some specific object]** are in this image.` 

For example, **we can ask "how many colors are in this image":**


### Image Matching
This task is formulated by a question: "From which part of image (1) is image (2) cropped?"

We ensure that image (2) is cropped from one of the left top, right top, left bottom, and right bottom of the image (1).

The motivation is humans can come up with the correct answer by a matching process, while neural networks are incapable of accomplishing such a process explicitly.

Therefore, even though it's a relatively simple task, it could be rather difficult for GPT4.

The following image shows that GPT4 **fails** for all four questions.

<div align="center">
    <img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/match1.png?raw=True" width="45%" alt="First Image" style="display: inline-block; margin: 5px;">
    <img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/match2.png?raw=True" width="45%" alt="Second Image" style="display: inline-block; margin: 5px;">
    <img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/match3.png?raw=True" width="45%" alt="Third Image" style="display: inline-block; margin: 5px;">
    <img src="https://github.com/ywugwu/ywugwu.github.io/blob/main/_posts/imgs/match4.png?raw=True" width="45%" alt="Third Image" style="display: inline-block; margin: 5px;">
    <br>
<!--     <em>Caption goes here</em> -->
</div>


### Perturbation Detection
This task is formulated by asking, "Are the two images identical? Do not use code analyzer."

By disabling GPT's code analyzer, we can see that GPT4's vision model can't distinguish minor difference between images.

<div align="center">
    <img src="https://github.com/ywugwu/ywugwu.github.io/assets/128890731/a28225cd-a78b-48ca-a510-ce6bb872f6db" width="45%">
    <br>
    <em>Image (1) and Image (2) are identical while GPT4 returns "not identical"</em>
</div>

<div align="center">
    <img src="https://github.com/ywugwu/ywugwu.github.io/assets/128890731/93670344-720b-4f68-8445-8f9b1defbb1f" width="45%">
    <br>
    <em>Image (2) differs from image (1) by adding a small white patch. Although GPT4 returns "not identical", the reasons are incorrect and it doesn't discover the white patch we add.</em>
</div>



## Findings (Limitations Identified)


## References

- OpenAI et al. (2023). *GPT-4 Technical Report*. arXiv:2303.08774 [cs.CL]. Available at: [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)
